{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "870dd856-ae2f-40c3-9608-13831cbe5032",
   "metadata": {},
   "source": [
    "<figure>\n",
    "  <IMG SRC=\"https://raw.githubusercontent.com/mbakker7/exploratory_computing_with_python/master/tudelft_logo.png\" WIDTH=250 ALIGN=\"right\">\n",
    "</figure>\n",
    "\n",
    "# MORE group project\n",
    "*WIM-data analysis*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d66bf189-89aa-47a0-93c1-f271e2afff44",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import matplotlib.colors\n",
    "import matplotlib.gridspec as gridspec\n",
    "from scipy import stats\n",
    "import pyvinecopulib as pv\n",
    "from scipy.stats import rankdata\n",
    "\n",
    "from py_banshee.rankcorr import bn_rankcorr\n",
    "from py_banshee.bn_plot import bn_visualize\n",
    "from py_banshee.d_cal import test_distance\n",
    "from py_banshee.copula_test import cvm_statistic\n",
    "from py_banshee.prediction import inference,conditional_margins_hist\n",
    "from py_banshee.sample_bn import generate_samples\n",
    "import pyvinecopulib as pv\n",
    "import networkx as nx"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d8dbeee4-2398-48b2-8f77-7d3053a2a074",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# List of axle load columns\n",
    "axle_load_columns = [\n",
    "    'axle 1 [kg]', 'axle 2 [kg]', 'axle 3 [kg]', 'axle 4 [kg]', 'axle 5 [kg]', \n",
    "    'axle 6 [kg]', 'axle 7 [kg]', 'axle 8 [kg]', 'axle 9 [kg]', 'axle 10 [kg]', \n",
    "    'axle 11 [kg]', 'axle 12 [kg]', 'axle 13 [kg]', 'axle 14 [kg]'\n",
    "]\n",
    "\n",
    "# List of spacing columns\n",
    "spacing_columns = [\n",
    "    'ax1 - ax2 [cm]', 'ax2 - ax3 [cm]', 'ax3 - ax4 [cm]', 'ax4 - ax5 [cm]', \n",
    "    'ax6 - ax7 [cm]', 'ax7 - ax8 [cm]', 'ax8 - ax9 [cm]', 'ax10 - ax11 [cm]', \n",
    "    'ax11 - ax12 [cm]', 'ax12 - ax13 [cm]', 'ax13 - ax14 [cm]'\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d39a7f0-54e8-44b7-a356-1e7849bb9887",
   "metadata": {},
   "source": [
    "## Importing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "83c05bff-c921-4fb0-83cd-3eff29c543bf",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "%%capture\n",
    "# Importing data and combining in 1 large dataframe\n",
    "data_left = pd.read_csv('DATA_RW_12L_April2013.csv', delimiter=';', skipinitialspace=True, index_col=False);\n",
    "data_right = pd.read_csv('DATA_RW_12R_April2013.csv', delimiter=';', skipinitialspace=True, index_col=False);\n",
    "combined_data = pd.concat([data_left, data_right], ignore_index=True)\n",
    "\n",
    "# Some renaming of columns and adding of new columns to make things easier\n",
    "combined_data.rename(columns={'ax3- ax4 [cm]': 'ax3 - ax4 [cm]'}, inplace=True)\n",
    "combined_data['wheelbase [cm]'] = combined_data[spacing_columns].sum(axis=1)\n",
    "combined_data['number_of_axles'] = combined_data[axle_load_columns].count(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3a159b-93d0-4f62-b781-430a6bd8434d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "combined_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f8dca4d-58cd-488f-a039-cc411e9fd501",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Cleaning data with filters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04286c24-0d13-49de-bed2-9e87efbda9a4",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Condition 1: Wheelbase < 1 meter\n",
    "condition_1 = combined_data['wheelbase [cm]'] < 100  \n",
    "\n",
    "# Condition 2: Wheelbase < 30m and spacing > 10m\n",
    "condition_2 = (combined_data['wheelbase [cm]'] < 3000) & ((combined_data['ax1 - ax2 [cm]'] > 1000) | (combined_data['ax13 - ax14 [cm]'] > 1000))\n",
    "\n",
    "# Condition 3: Wheelbase > 40 meters\n",
    "condition_3 = combined_data['wheelbase [cm]'] > 4000  \n",
    "\n",
    "# Condition 4: Axle load <= 0 tons\n",
    "condition_4 = (combined_data[axle_load_columns].le(0)).any(axis=1)\n",
    "\n",
    "# Condition 5: Axle load > 40 tons\n",
    "condition_5 = (combined_data[axle_load_columns].gt(40000)).any(axis=1)\n",
    "\n",
    "# Condition 6: Axle weight > 15 tons and > 85% of gross vehicle weight\n",
    "condition_6 = (combined_data[axle_load_columns].max(axis=1) > 15000) & (combined_data[axle_load_columns].max(axis=1) / combined_data['mass [kg]'] > 0.85)\n",
    "\n",
    "# Condition 7: Gross vehicle weight <= 0 tons\n",
    "condition_7 = combined_data['mass [kg]'] <= 0  \n",
    "\n",
    "# Condition 8: Sum of axle loads not within 50kg of gross vehicle weight\n",
    "sum_axle_loads = combined_data[axle_load_columns].sum(axis=1)\n",
    "condition_8 = (abs(sum_axle_loads - combined_data['mass [kg]']) > 50)\n",
    "\n",
    "# Condition 9: less or equal to 2 m first two axles, one of which is larger than 10 tons and over 2.5 times heavier than other axle.\n",
    "closely_spaced = combined_data['ax1 - ax2 [cm]'] <= 200\n",
    "axle1_load = combined_data['axle 1 [kg]']\n",
    "axle2_load = combined_data['axle 2 [kg]']\n",
    "one_axle_heavy = (axle1_load > 10000) | (axle2_load > 10000)\n",
    "axle_weight_ratio = (axle1_load / axle2_load > 2.5) | (axle2_load / axle1_load > 2.5)\n",
    "condition_9 = closely_spaced & one_axle_heavy & axle_weight_ratio\n",
    "\n",
    "# Condition 10: First spacing between the first two axles larger than 15m\n",
    "condition_10 = combined_data['ax1 - ax2 [cm]'] > 1500  \n",
    "\n",
    "# Condition 11: Any spacing less than 0.4 meters\n",
    "condition_11 = combined_data[spacing_columns].min(axis=1) < 40  # Less than 0.4 meters\n",
    "\n",
    "# Condition 12: Mismatch between number of axle spacings and number of axle loads\n",
    "condition_12 = combined_data[axle_load_columns].count(axis=1) != (combined_data[spacing_columns].count(axis=1) + 1)\n",
    "\n",
    "## Condition 13: Sum of axle spacings not within 50 mm of wheelbase.\n",
    "## Unfortunately, we didn't have a seperate column for wheelbase in our csv file, so we cant do this calculation. We just added one ourselfs by summing the axle spacing, so comparing them would result in zero difference for all vehicles.\n",
    "\n",
    "#Condition 14: Number of axles below or equal to 1.\n",
    "condition_14 = combined_data[axle_load_columns].count(axis=1) <= 1\n",
    "\n",
    "#Condition 15: First axle spacing in the interval of 10 m–15 m.\n",
    "condition_15 = (combined_data['ax1 - ax2 [cm]'] >= 1000) & (combined_data['ax1 - ax2 [cm]'] <= 1500)\n",
    "\n",
    "#Condition 16: 16.\tEach spacing in range of 0,4 m–0,7 m.\n",
    "condition_16 = combined_data[spacing_columns].ge(40).all(axis=1) & combined_data[spacing_columns].lt(70).all(axis=1)\n",
    "\n",
    "#Condition 17: Each spacing in range of 0,7 m–1,0 m.\n",
    "condition_17 = combined_data[spacing_columns].ge(70).all(axis=1) & combined_data[spacing_columns].lt(100).all(axis=1)\n",
    "\n",
    "#Condition 18: Each axle load in the interval of 25 tons–40 tons.\n",
    "condition_18 = combined_data[axle_load_columns].ge(25000).all(axis=1) & combined_data[axle_load_columns].lt(40000).all(axis=1)\n",
    "\n",
    "#Condition 19: Each axle load below 0,5 tons.\n",
    "condition_19 = combined_data[axle_load_columns].lt(500).all(axis=1)\n",
    "\n",
    "#Condition 20: Vehicles with same WIM identification number (ID).\n",
    "condition_20 = combined_data.duplicated(subset='ID', keep=False)\n",
    "\n",
    "#Condition 21: Vehicles with a gross vehicle weight below 3,56 tons.\n",
    "condition_21 = combined_data['mass [kg]'] < 3560\n",
    "\n",
    "#Condition 22: Vehicles with a gross vehicle weight above 112 tons.\n",
    "condition_22 = combined_data['mass [kg]'] > 112000\n",
    "\n",
    "#Condition 23: Vehicles with a speed greater than 120 km/h.\n",
    "condition_23 = (combined_data['velocity [km/h]'] > 120) | (combined_data['velocity [km/h]'] < 60)\n",
    "\n",
    "#Condition 24: The vehicles with gross vehicle weight larger than 71.3 tons and or length bumper-to-bumper above than 25,5 m and axle spacing above 12,5 m (data related to a combination of two vehicles).\n",
    "condition_24 = (\n",
    "    (combined_data['mass [kg]'] > 71300) |\n",
    "    (\n",
    "        (combined_data['length [cm]'] > 2550) &\n",
    "        (combined_data[spacing_columns].max(axis=1) > 1250)\n",
    "    )\n",
    ")\n",
    "\n",
    "#Condition 25: Vehicles with inter axle distances less than 75 cm.\n",
    "condition_25 = combined_data[spacing_columns].min(axis=1) < 75\n",
    "\n",
    "#Condition 26: Duplicate records.\n",
    "condition_26 = combined_data.duplicated(keep=False)\n",
    "\n",
    "condition_27 = combined_data['number_of_axles'] > 7\n",
    "\n",
    "# Combine all conditions\n",
    "filter_out_conditions = condition_1 | condition_2 | condition_3 | condition_4 | condition_5 | \\\n",
    "                         condition_6 | condition_7 | condition_8 | condition_10 | condition_11 | \\\n",
    "                          condition_12 | condition_14 | condition_15 | condition_16 | condition_17 | \\\n",
    "                           condition_18 | condition_19 | condition_20 | condition_21 | condition_22 | \\\n",
    "                            condition_23 | condition_24 | condition_25 | condition_26 | condition_27\n",
    "\n",
    "# Keep only rows that do NOT meet any of these conditions\n",
    "cleaned_data = combined_data[~filter_out_conditions]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1336471-a5e7-4237-947b-4be8a2ed9a49",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print(len(combined_data[condition_27]))\n",
    "#print(combined_data[condition_12].index)\n",
    "#print(combined_data.iloc[combined_data[condition_12].index, 20:35])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33297573-b6d7-44d7-8044-9593206a410b",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(len(cleaned_data), len(combined_data))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b305cfd-5731-4a7c-bd31-9e5a673eaaa2",
   "metadata": {},
   "source": [
    "## Data compatibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7119c8-222d-4a9a-813a-4a0d957367ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = cleaned_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "50f6e891-db48-4a34-89e5-779c302c4286",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count the number of vehicles for each number of axles\n",
    "axle_counts = data['number_of_axles'].value_counts().sort_index()\n",
    "\n",
    "print(axle_counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5ea498-4363-4b53-8d02-257ef1438175",
   "metadata": {},
   "outputs": [],
   "source": [
    "unique_subcategories = data['subcat'].unique()\n",
    "num_unique_subcategories = len(unique_subcategories)\n",
    "unique_subcategories_counts = data['subcat'].value_counts()\n",
    "\n",
    "print(f\"Number of unique subcategories: {num_unique_subcategories}\")\n",
    "print(\"List of unique subcategories:\")\n",
    "print(np.array(unique_subcategories_counts.index))\n",
    "print(np.array(unique_subcategories_counts))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f0e1dba-d088-426c-8229-1aab60026abe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for buses (subcategories starting with 'B')\n",
    "buses_data = data[data['subcat'].str.startswith('R')]\n",
    "\n",
    "# Count the number of buses by number of axles\n",
    "buses_axle_counts = buses_data['number_of_axles'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each number of axles\n",
    "buses_axle_percentages = (buses_axle_counts / buses_axle_counts.sum()) * 100\n",
    "\n",
    "# Display the result\n",
    "print(buses_axle_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3249a1ac-43ed-4cbb-88c6-0ff21a8ffcc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter for single-unit multi-axle vehicles (subcategories starting with 'V') with 4 or more axles\n",
    "multi_axle_vehicles = data[(data['subcat'].str.startswith('V')) & (data['number_of_axles'] >= 4)]\n",
    "\n",
    "# Count the number of vehicles by number of axles\n",
    "multi_axle_counts = multi_axle_vehicles['number_of_axles'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each number of axles\n",
    "multi_axle_percentages = (multi_axle_counts / multi_axle_counts.sum()) * 100\n",
    "\n",
    "# Display the result\n",
    "print(multi_axle_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64751171-de34-4854-9ccc-459123280ba1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for HGVs with 3 or 4 articulated axles\n",
    "articulated_hgvs = data[(data['subcat'].str.startswith('T')) & (data['number_of_axles'] >= 3) & (data['number_of_axles'] <= 4)]\n",
    "\n",
    "# Count the number of vehicles by number of axles\n",
    "multi_axle_counts = articulated_hgvs['number_of_axles'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each number of axles\n",
    "multi_axle_percentages = (multi_axle_counts / multi_axle_counts.sum()) * 100\n",
    "\n",
    "# Display the result\n",
    "print(multi_axle_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05bb09fe-682a-4af8-915d-efa9d32c937c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Filter the data for HGVs with 3 or 4 articulated axles\n",
    "articulated_hgvs = data[(data['subcat'].str.startswith('T')) & (data['number_of_axles'] >= 6)]\n",
    "\n",
    "# Count the number of vehicles by number of axles\n",
    "multi_axle_counts = articulated_hgvs['number_of_axles'].value_counts()\n",
    "\n",
    "# Calculate the percentage for each number of axles\n",
    "multi_axle_percentages = (multi_axle_counts / multi_axle_counts.sum()) * 100\n",
    "\n",
    "# Display the result\n",
    "print(multi_axle_percentages)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b967e96-967b-4cdd-a913-1226de890851",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the unique number of axles in the dataset\n",
    "unique_axles = data['number_of_axles'].unique()\n",
    "\n",
    "# Create a dictionary to store dataframes for each axle count\n",
    "axle_dataframes = {}\n",
    "\n",
    "# Loop through unique axle counts and create separate dataframes\n",
    "for axles in unique_axles:\n",
    "    axle_dataframes[f'axles_{axles}'] = data[data['number_of_axles'] == axles]\n",
    "\n",
    "# Check the keys of the dictionary to see all available dataframes\n",
    "print(axle_dataframes.keys())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "64abeab5-eeca-4e44-bd55-d3e2e8c0a22c",
   "metadata": {},
   "source": [
    "## Initial data analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e9a8bce-58b9-4c6b-a416-7266bddeabfc",
   "metadata": {},
   "outputs": [],
   "source": [
    "axle_load_columns = [\n",
    "    'axle 1 [kg]', 'axle 2 [kg]', 'axle 3 [kg]', 'axle 4 [kg]', 'axle 5 [kg]', \n",
    "    'axle 6 [kg]', 'axle 7 [kg]'\n",
    "]\n",
    "data[axle_load_columns].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dec8ab7-f898-4b57-b610-8a60866c7c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "spacing_columns = [\n",
    "    'ax1 - ax2 [cm]', 'ax2 - ax3 [cm]', 'ax3 - ax4 [cm]', 'ax4 - ax5 [cm]', \n",
    "    'ax6 - ax7 [cm]', 'ax7 - ax8 [cm]'\n",
    "]\n",
    "data[spacing_columns].describe().round(2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c4cdfef-ce44-44a2-b72f-e8088ba97397",
   "metadata": {},
   "outputs": [],
   "source": [
    "data['number_of_axles'].value_counts(ascending=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ae7b6b-ad3e-4b76-bef3-067612a3f158",
   "metadata": {},
   "outputs": [],
   "source": [
    "def unity(data):\n",
    "    M = data.shape[0]  # Reading number of observations per node\n",
    "    ranks = data.rank(axis=0)\n",
    "    u_hat = ranks / (M + 1)\n",
    "    return u_hat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63192ba9-5444-45d0-8566-5c1044ad7b83",
   "metadata": {},
   "outputs": [],
   "source": [
    "def sd_normal(data):\n",
    "    M = data.shape[0]  # Reading number of observations per node\n",
    "    ranks = data.rank(axis=0)\n",
    "    u_hat = ranks / (M + 1)\n",
    "    sd_data = stats.norm.ppf(u_hat)\n",
    "    return sd_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d811eac-c05b-4f2f-83b1-364e8af78f91",
   "metadata": {},
   "source": [
    "## Seperated dataframes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33e411a1-30e6-4c69-bc9c-1be9524011db",
   "metadata": {},
   "outputs": [],
   "source": [
    "data2 = axle_dataframes['axles_2'][[\n",
    "    'axle 1 [kg]', 'axle 2 [kg]'\n",
    "]]\n",
    "data3 = axle_dataframes['axles_3'][[\n",
    "    'axle 1 [kg]', 'axle 2 [kg]', 'axle 3 [kg]'\n",
    "]]\n",
    "data4 = axle_dataframes['axles_4'][[\n",
    "    'axle 1 [kg]', 'axle 2 [kg]', 'axle 3 [kg]', 'axle 4 [kg]'\n",
    "]]\n",
    "data5 = axle_dataframes['axles_5'][[\n",
    "    'axle 1 [kg]', 'axle 2 [kg]', 'axle 3 [kg]', 'axle 4 [kg]', 'axle 5 [kg]'\n",
    "]]\n",
    "data6 = axle_dataframes['axles_6'][[\n",
    "    'axle 1 [kg]', 'axle 2 [kg]', 'axle 3 [kg]', 'axle 4 [kg]', 'axle 5 [kg]', \n",
    "    'axle 6 [kg]'\n",
    "]]\n",
    "data7 = axle_dataframes['axles_7'][[\n",
    "    'axle 1 [kg]', 'axle 2 [kg]', 'axle 3 [kg]', 'axle 4 [kg]', 'axle 5 [kg]', \n",
    "    'axle 6 [kg]', 'axle 7 [kg]'\n",
    "]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770482ec-9987-4204-a725-fc810140659a",
   "metadata": {},
   "outputs": [],
   "source": [
    "unity_data2 = unity(data2)\n",
    "unity_data3 = unity(data3)\n",
    "unity_data4 = unity(data4)\n",
    "unity_data5 = unity(data5)\n",
    "unity_data6 = unity(data6)\n",
    "unity_data7 = unity(data7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb00c188-9917-4048-a1c9-6f3d60732f9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sd_data2 = pd.DataFrame(sd_normal(data2), columns = data2.columns)\n",
    "sd_data3 = pd.DataFrame(sd_normal(data3), columns = data3.columns)\n",
    "sd_data4 = pd.DataFrame(sd_normal(data4), columns = data4.columns)\n",
    "sd_data5 = pd.DataFrame(sd_normal(data5), columns = data5.columns)\n",
    "sd_data6 = pd.DataFrame(sd_normal(data6), columns = data6.columns)\n",
    "sd_data7 = pd.DataFrame(sd_normal(data7), columns = data7.columns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cd2768e-d69e-4c75-b480-beccace615c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def ecdf(data):\n",
    "    \"\"\"Compute ECDF\"\"\"\n",
    "    x = np.sort(data)\n",
    "    n = x.size\n",
    "    y = np.arange(1, n + 1) / n\n",
    "    return x, y\n",
    "\n",
    "# List of datasets and their labels\n",
    "datasets = [data2, data3, data4, data5, data6, data7]\n",
    "labels = ['2 Axles', '3 Axles', '4 Axles', '5 Axles', '6 Axles', '7 Axles']\n",
    "\n",
    "# Colors for different datasets\n",
    "colors = ['black', 'violet', 'orange', 'green', 'blue', 'red']\n",
    "\n",
    "# Number of axle columns to plot\n",
    "max_axles = max([len(data.columns) for data in datasets])\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, max_axles, figsize=(20, 5), sharey=True)\n",
    "fig.suptitle('CDF of Axle Loads by Axle Position', fontsize=16)\n",
    "\n",
    "# Plotting\n",
    "for axle_idx in range(max_axles):\n",
    "    ax = axes[axle_idx]\n",
    "    for dataset, label, color in zip(datasets, labels, colors):\n",
    "        if f'axle {axle_idx + 1} [kg]' in dataset.columns:\n",
    "            x, y = ecdf(dataset[f'axle {axle_idx + 1} [kg]'])\n",
    "            ax.plot(x, y, label=label, color=color)\n",
    "    ax.set_title(f'Axle {axle_idx + 1}')\n",
    "    ax.set_xlabel('Axle Load (kg)')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim([0, 20000])\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Adjust layout\n",
    "axes[0].set_ylabel('CDF')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)  # Adjust space for the main title\n",
    "plt.savefig(\"WIM_cdf.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0edb30e0-1c9d-48b2-ab94-67319f920d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# List of datasets and their labels\n",
    "datasets = [data2, data3, data4, data5, data6, data7]\n",
    "labels = ['2 Axles', '3 Axles', '4 Axles', '5 Axles', '6 Axles', '7 Axles']\n",
    "\n",
    "# Colors for different datasets\n",
    "colors = ['black', 'violet', 'orange', 'green', 'blue', 'red']\n",
    "\n",
    "# Number of axle columns to plot\n",
    "max_axles = max([len(data.columns) for data in datasets])\n",
    "\n",
    "# Create subplots\n",
    "fig, axes = plt.subplots(1, max_axles, figsize=(20, 5), sharey=True)\n",
    "fig.suptitle('PDF of Axle Loads by Axle Position', fontsize=16)\n",
    "\n",
    "# Plotting\n",
    "for axle_idx in range(max_axles):\n",
    "    ax = axes[axle_idx]\n",
    "    for dataset, label, color in zip(datasets, labels, colors):\n",
    "        if f'axle {axle_idx + 1} [kg]' in dataset.columns:\n",
    "            # Plot the PDF using Seaborn's kdeplot\n",
    "            sns.kdeplot(dataset[f'axle {axle_idx + 1} [kg]'], ax=ax, label=label, color=color, fill=False)\n",
    "    ax.set_title(f'Axle {axle_idx + 1}')\n",
    "    ax.set_xlabel('Axle Load (kg)')\n",
    "    ax.grid(True)\n",
    "    ax.set_xlim([0, 20000])  # You can adjust the range as necessary\n",
    "    ax.legend(fontsize=8)\n",
    "\n",
    "# Adjust layout\n",
    "axes[0].set_ylabel('PDF')\n",
    "plt.tight_layout()\n",
    "plt.subplots_adjust(top=0.85)  # Adjust space for the main title\n",
    "plt.savefig(\"WIM_pdf.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2e1cf855-78f5-410a-99d6-f541f4f0cbf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(unity_data7, kind='scatter', height=2)\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd6372b-62d7-4e9b-8ad9-efc48148a36c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#sns.pairplot(sd_data7, height=2,plot_kws=dict(size=.1))\n",
    "#plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64111afc-2c0b-4abf-8c79-d9a73ccfb816",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Calculate the rank correlation matrix\n",
    "R_e = data3.corr(method='spearman').values\n",
    "\n",
    "#Transform data to standard normal and store it in a DataFrame\\\n",
    "unity_data = unity_data3\n",
    "\n",
    "standard_data = pd.DataFrame(data=stats.norm.ppf(unity_data), columns=unity_data.columns)\n",
    "\n",
    "#Compute pearson correlation matrix\n",
    "rho_N = np.corrcoef(standard_data, rowvar=False)\n",
    "\n",
    "#Transform to rank correlation matrix\n",
    "R_N = (6 / np.pi) * np.arcsin(rho_N / 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b39df845-90c3-417c-b0f4-fd0d6d32ed76",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot\n",
    "nam = unity_data.columns\n",
    "px = list(range(len(nam)))\n",
    "\n",
    "fig, axes = plt.subplots(1,2, figsize=(15,6), layout='constrained')\n",
    "im1=axes[0].imshow(R_e, cmap='Blues', vmin=-1, vmax=1)\n",
    "axes[0].set_xticks(px, nam, rotation=90)\n",
    "axes[0].set_yticks(px, nam)\n",
    "axes[0].set_title('Observed rank correlations',fontsize=18)\n",
    "zz2 = np.round(R_e, 2)\n",
    "zz = zz2.astype(str)\n",
    "for i in range(len(nam)):\n",
    "    for j in range(len(nam)):\n",
    "        if zz2[i,j]>0.5:\n",
    "            color = 'w'\n",
    "        else:\n",
    "            color = 'k'\n",
    "        axes[0].text(j, i, zz[i, j],\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        fontsize=14, color=color)\n",
    "\n",
    "im1=axes[1].imshow(R_N, cmap='Blues', vmin=-1, vmax=1)\n",
    "axes[1].set_xticks(px, nam, rotation=90)\n",
    "axes[1].set_yticks(px, nam)\n",
    "axes[1].set_title('Normal rank correlations',fontsize=18)\n",
    "zz2 = np.round(R_N, 2)\n",
    "zz = zz2.astype(str)\n",
    "for i in range(len(nam)):\n",
    "    for j in range(len(nam)):\n",
    "        if zz2[i,j]>0.5:\n",
    "            color = 'w'\n",
    "        else:\n",
    "            color = 'k'\n",
    "        axes[1].text(j, i, zz[i, j],\n",
    "                        ha=\"center\", va=\"center\",\n",
    "                        fontsize=14, color=color)\n",
    "        \n",
    "cbar = fig.colorbar(im1,ax=axes[1], fraction=0.05, pad=0.04)\n",
    "#plt.savefig(\"Rankcorr_2axles.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8b3046c4-d5d5-4246-b6dc-74fbe8acc2c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import networkx as nx\n",
    "\n",
    "# Create a directed graph\n",
    "G = nx.DiGraph()\n",
    "\n",
    "# Add nodes (representing axles)\n",
    "G.add_nodes_from([\"X5,1\", \"X5,2\", \"X5,3\", \"X5,4\", \"X5,5\"])\n",
    "G.add_nodes_from([\"X4,1\", \"X4,2\", \"X4,3\", \"X4,4\"])\n",
    "G.add_nodes_from([\"X3,1\", \"X3,2\", \"X3,3\"])\n",
    "G.add_nodes_from([\"X2,1\", \"X2,2\"])\n",
    "G.add_nodes_from([\"GVW\"])\n",
    "G.add_nodes_from([\"X6,1\", \"X6,2\", \"X6,3\", \"X6,4\", \"X6,5\", \"X6,6\"])\n",
    "G.add_nodes_from([\"X7,1\", \"X7,2\", \"X7,3\", \"X7,4\", \"X7,5\", \"X7,6\", \"X7,7\"])\n",
    "\n",
    "# Add directed edges based on physical understanding and correlations\n",
    "# Normal edges\n",
    "normal_edges = [(\"X5,1\", \"X5,2\"), (\"X5,2\", \"X5,3\"), (\"X5,3\", \"X5,4\"), (\"X5,4\", \"X5,5\"),\n",
    "                (\"X4,1\", \"X4,2\"), (\"X4,2\", \"X4,3\"), (\"X4,3\", \"X4,4\"),\n",
    "                (\"X3,1\", \"X3,2\"), (\"X3,2\", \"X3,3\"),\n",
    "                (\"X2,1\", \"X2,2\"),\n",
    "                (\"X6,1\", \"X6,2\"), (\"X6,2\", \"X6,3\"), (\"X6,3\", \"X6,4\"), (\"X6,4\", \"X6,5\"), (\"X6,5\", \"X6,6\"),\n",
    "                (\"X7,1\", \"X7,2\"), (\"X7,2\", \"X7,3\"), (\"X7,3\", \"X7,4\"), (\"X7,4\", \"X7,5\"), (\"X7,5\", \"X7,6\"), (\"X7,6\", \"X7,7\")]\n",
    "\n",
    "# Thin edges to GVW\n",
    "thin_edges = [(\"X5,1\", \"GVW\"), (\"X5,2\", \"GVW\"), (\"X5,3\", \"GVW\"), (\"X5,4\", \"GVW\"), (\"X5,5\", \"GVW\"),\n",
    "              (\"X4,1\", \"GVW\"), (\"X4,2\", \"GVW\"), (\"X4,3\", \"GVW\"), (\"X4,4\", \"GVW\"),\n",
    "              (\"X3,1\", \"GVW\"), (\"X3,2\", \"GVW\"), (\"X3,3\", \"GVW\"),\n",
    "              (\"X2,1\", \"GVW\"), (\"X2,2\", \"GVW\"),\n",
    "              (\"X6,1\", \"GVW\"), (\"X6,2\", \"GVW\"), (\"X6,3\", \"GVW\"), (\"X6,4\", \"GVW\"), (\"X6,5\", \"GVW\"), (\"X6,6\", \"GVW\"),\n",
    "              (\"X7,1\", \"GVW\"), (\"X7,2\", \"GVW\"), (\"X7,3\", \"GVW\"), (\"X7,4\", \"GVW\"), (\"X7,5\", \"GVW\"), (\"X7,6\", \"GVW\"), (\"X7,7\", \"GVW\")]\n",
    "\n",
    "G.add_edges_from(normal_edges)\n",
    "G.add_edges_from(thin_edges)\n",
    "\n",
    "# Define positions for the nodes\n",
    "pos = {'X5,1': (0, 2), 'X5,2': (1, 2), 'X5,3': (2, 2), 'X5,4': (3, 2), 'X5,5': (4, 2), \n",
    "       'X4,1': (0, 3), 'X4,2': (1, 3), 'X4,3': (2, 3), 'X4,4': (3, 3),\n",
    "       'X3,1': (0, 4), 'X3,2': (1, 4), 'X3,3': (2, 4),\n",
    "       'X2,1': (0, 5), 'X2,2': (1, 5),\n",
    "       'GVW' : (0, 6),\n",
    "       'X6,1': (0, 1), 'X6,2': (1, 1), 'X6,3': (2, 1), 'X6,4': (3, 1), 'X6,5': (4, 1), 'X6,6': (5, 1),\n",
    "       'X7,1': (0, 0), 'X7,2': (1, 0), 'X7,3': (2, 0), 'X7,4': (3, 0), 'X7,5': (4, 0), 'X7,6': (5, 0), 'X7,7': (6, 0)}\n",
    "\n",
    "# Draw edges with arrows and different styles\n",
    "plt.figure(figsize=(12, 10))\n",
    "\n",
    "# Draw normal edges with arrows\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos, edgelist=normal_edges, width=1, edge_color='black', arrowstyle='-|>', arrowsize=10, node_size=2000\n",
    ")\n",
    "\n",
    "# Draw thin edges to GVW with arrows\n",
    "nx.draw_networkx_edges(\n",
    "    G, pos, edgelist=thin_edges, width=0.5, alpha=0.5, edge_color='black', arrowstyle='-', arrowsize=5, node_size=2000\n",
    ")\n",
    "\n",
    "# Draw nodes and labels\n",
    "nx.draw_networkx_nodes(G, pos, node_size=2000, node_color='skyblue')\n",
    "nx.draw_networkx_labels(G, pos, font_size=12, font_weight='bold')\n",
    "\n",
    "# Add title and save\n",
    "plt.title(\"DAG Representing Axle Load Dependence\")\n",
    "#plt.savefig(\"DAG.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ddcd5f3-37c4-4ff5-824f-17f6371c2c07",
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings  \n",
    "warnings.filterwarnings(\"ignore\")\n",
    "\n",
    "plt.figure(figsize=(3,1))\n",
    "uniform_data = unity_data7.reset_index(drop=True)\n",
    "variable_names = unity_data7.columns.tolist()\n",
    "M = cvm_statistic(uniform_data, names=variable_names, plot=True, fig_name='cvm_statistics_plot')\n",
    "print(M)\n",
    "plt.savefig(\"CvM_7axles.png\", dpi=300, bbox_inches='tight')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78443173-1bce-40ea-a316-cfa80077ea3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "names7 = list(data7.columns)\n",
    "print(names7)\n",
    "\n",
    "N = data7.shape[1] # number of nodes\n",
    "parents7 = [None]*N  # create an empty list \n",
    "\n",
    "parents7[0] = []          \n",
    "parents7[1] = [0]            \n",
    "parents7[2] = [1]      \n",
    "parents7[3] = [2] \n",
    "parents7[4] = [3] \n",
    "parents7[5] = [4] \n",
    "parents7[6] = [5] \n",
    "\n",
    "len(parents7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15d0d041-e4f7-49e2-a80c-91c7100fd8dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "names6 = list(data6.columns)\n",
    "print(names6)\n",
    "\n",
    "N = data6.shape[1] # number of nodes\n",
    "parents6 = [None]*N  # create an empty list \n",
    "\n",
    "parents6[0] = []          \n",
    "parents6[1] = [0]            \n",
    "parents6[2] = [1]      \n",
    "parents6[3] = [2] \n",
    "parents6[4] = [3] \n",
    "parents6[5] = [4] \n",
    "\n",
    "len(parents6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a46455e4-e5b2-40df-99a4-a32e15c48c92",
   "metadata": {},
   "outputs": [],
   "source": [
    "names5 = list(data5.columns)\n",
    "print(names5)\n",
    "\n",
    "N = data5.shape[1] # number of nodes\n",
    "parents5 = [None]*N  # create an empty list \n",
    "\n",
    "parents5[0] = []          \n",
    "parents5[1] = [0]            \n",
    "parents5[2] = [1]      \n",
    "parents5[3] = [2] \n",
    "parents5[4] = [3] \n",
    "\n",
    "len(parents5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fd98e7a-9b19-410d-8dd2-a34dc6cf5514",
   "metadata": {},
   "outputs": [],
   "source": [
    "names4 = list(data4.columns)\n",
    "print(names4)\n",
    "\n",
    "N = data4.shape[1] # number of nodes\n",
    "parents4 = [None]*N  # create an empty list \n",
    "\n",
    "parents4[0] = []          \n",
    "parents4[1] = [0]            \n",
    "parents4[2] = [1]      \n",
    "parents4[3] = [2] \n",
    "\n",
    "len(parents4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c496e06b-7ff5-4819-b3ea-513fe6cd86fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "names3 = list(data3.columns)\n",
    "print(names3)\n",
    "\n",
    "N = data3.shape[1] # number of nodes\n",
    "parents3 = [None]*N  # create an empty list \n",
    "\n",
    "parents3[0] = []          \n",
    "parents3[1] = [0]            \n",
    "parents3[2] = [1]      \n",
    "\n",
    "len(parents3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6993bd8-7413-42e9-b234-c5a7e0ad02f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "names2 = list(data2.columns)\n",
    "print(names2)\n",
    "\n",
    "N = data2.shape[1] # number of nodes\n",
    "parents2 = [None]*N  # create an empty list \n",
    "\n",
    "parents2[0] = []          \n",
    "parents2[1] = [0]                  \n",
    "\n",
    "len(parents2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7aa087bc-d68d-4e43-ba65-df2756480231",
   "metadata": {},
   "outputs": [],
   "source": [
    "R_BN_7= bn_rankcorr(parents7, data7, var_names=names7, is_data=True, plot=True)\n",
    "R_BN_6= bn_rankcorr(parents6, data6, var_names=names6, is_data=True, plot=True)\n",
    "R_BN_5= bn_rankcorr(parents5, data5, var_names=names5, is_data=True, plot=True)\n",
    "R_BN_4= bn_rankcorr(parents4, data4, var_names=names4, is_data=True, plot=True)\n",
    "R_BN_3= bn_rankcorr(parents3, data3, var_names=names3, is_data=True, plot=True)\n",
    "R_BN_2= bn_rankcorr(parents2, data2, var_names=names2, is_data=True, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d18e8d1-e11d-4017-96e5-89e2c805f3c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "counts2023 = pd.read_csv('counts_filtered_2023.csv', delimiter=',', skipinitialspace=True, index_col=False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f975ae06-49b3-448a-b756-4b4705fe3da0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Axle distribution\n",
    "axle_distribution = {\n",
    "    'buses_and_coaches': {2: 0.573, 3: 0.427},\n",
    "    'HGVs_2_rigid_axle': {2: 1.0},\n",
    "    'HGVs_3_rigid_axle': {3: 1.0},\n",
    "    'HGVs_4_or_more_rigid_axle': {4: 0.531, 5: 0.328, 6: 0.115, 7: 0.027},\n",
    "    'HGVs_3_or_4_articulated_axle': {3: 0.176, 4: 0.824},\n",
    "    'HGVs_5_articulated_axle': {5: 1.0},\n",
    "    'HGVs_6_articulated_axle': {3: 0.038, 4: 0.962}\n",
    "}\n",
    "\n",
    "# Initialize axle columns\n",
    "counts2023['2_axle'] = 0\n",
    "counts2023['3_axle'] = 0\n",
    "counts2023['4_axle'] = 0\n",
    "counts2023['5_axle'] = 0\n",
    "counts2023['6_axle'] = 0\n",
    "counts2023['7_axle'] = 0\n",
    "\n",
    "# Apply distributions\n",
    "for category, distribution in axle_distribution.items():\n",
    "    for axle, ratio in distribution.items():\n",
    "        counts2023[f'{axle}_axle'] += (counts2023[category] * ratio).round().astype(int)\n",
    "\n",
    "# Drop original vehicle classification columns\n",
    "counts2023 = counts2023.drop(columns=list(axle_distribution.keys()), inplace=False)\n",
    "\n",
    "# Display final DataFrame\n",
    "display(counts2023)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f665f53b-f118-4ba8-b34d-67165d734e8c",
   "metadata": {},
   "outputs": [],
   "source": [
    "array = []\n",
    "# Iterate over rows in the dataframe\n",
    "for i in range(len(counts2023)):\n",
    "    \n",
    "    # Generate samples for each axle type\n",
    "    a = generate_samples(R_BN_2, counts2023.iloc[i]['2_axle'], names=names2, data=data2)\n",
    "    b = generate_samples(R_BN_3, counts2023.iloc[i]['3_axle'], names=names3, data=data3)\n",
    "    c = generate_samples(R_BN_4, counts2023.iloc[i]['4_axle'], names=names4, data=data4)\n",
    "    d = generate_samples(R_BN_5, counts2023.iloc[i]['5_axle'], names=names5, data=data5)\n",
    "    e = generate_samples(R_BN_6, counts2023.iloc[i]['6_axle'], names=names6, data=data6)\n",
    "    f = generate_samples(R_BN_7, counts2023.iloc[i]['7_axle'], names=names7, data=data7)\n",
    "    \n",
    "    # Concatenate all axle type samples for this row\n",
    "    combined_row_df = pd.concat([a, b, c, d, e, f], ignore_index=True)\n",
    "    array.append(combined_row_df)     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b38b92c-2d5b-4220-bf38-da75013c5012",
   "metadata": {},
   "outputs": [],
   "source": [
    "len(array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7314bfd1-acb0-4dca-a30b-ff216bcf869c",
   "metadata": {},
   "outputs": [],
   "source": [
    "array[1000]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31d74b06-076f-4e41-86f2-4b98f8d2a488",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.sum([counts2023.iloc[1000]['2_axle'],\n",
    "        counts2023.iloc[1000]['3_axle'],\n",
    "        counts2023.iloc[1000]['4_axle'],\n",
    "        counts2023.iloc[1000]['5_axle'],\n",
    "        counts2023.iloc[1000]['6_axle'],\n",
    "        counts2023.iloc[1000]['7_axle']])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e0fa10-eb4f-41a4-ad90-3f9d5d7c9610",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
